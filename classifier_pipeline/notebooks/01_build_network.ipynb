{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Ingredient Co-occurrence Network\n",
        "\n",
        "This notebook builds a network of recipes based on ingredient co-occurrences. The network will be used for:\n",
        "1. Infusion recipe suggestions (combining ingredients from different cuisines)\n",
        "2. Cuisine classification (predicting cuisine from ingredient lists)\n",
        "\n",
        "## Overview\n",
        "\n",
        "The network construction process:\n",
        "1. Load encoded recipe data from preprocessing pipeline\n",
        "2. Compute ingredient co-occurrence statistics\n",
        "3. Build NetworkX graph with ingredients as nodes and co-occurrences as edges\n",
        "4. Analyze network properties (centrality, communities, etc.)\n",
        "5. Save network for use in inference tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline root: c:\\Users\\georg.DESKTOP-2FS9VF1\\source\\repos\\699-capstone-team14\\classifier_pipeline\n",
            "Python path includes: True\n"
          ]
        }
      ],
      "source": [
        "# Setup: Add classifier_pipeline to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add classifier_pipeline directory to path\n",
        "pipeline_root = Path.cwd().parent\n",
        "if str(pipeline_root) not in sys.path:\n",
        "    sys.path.insert(0, str(pipeline_root))\n",
        "\n",
        "print(f\"Pipeline root: {pipeline_root}\")\n",
        "print(f\"Python path includes: {pipeline_root.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded:\n",
            "  Input path: ../../preprocess_pipeline/data/combined_raw_datasets_with_cuisine_encoded.parquet\n",
            "  Ingredients column: encoded_ingredients\n",
            "  Cuisine column: cuisine_encoded\n",
            "\n",
            "  Network parameters:\n",
            "    - Min co-occurrence: 1\n",
            "    - Weight method: frequency\n",
            "    - Min ingredient frequency: 2\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Load configuration\n",
        "config_path = Path(\"../config/network_config.yaml\")\n",
        "\n",
        "if config_path.exists():\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    print(\"Configuration loaded:\")\n",
        "    data_cfg = config.get('data', {})\n",
        "    network_cfg = config.get('network', {})\n",
        "    \n",
        "    print(f\"  Input path: {data_cfg.get('input_path', 'N/A')}\")\n",
        "    print(f\"  Ingredients column: {data_cfg.get('ingredients_col', 'N/A')}\")\n",
        "    print(f\"  Cuisine column: {data_cfg.get('cuisine_col', 'N/A')}\")\n",
        "    print(f\"\\n  Network parameters:\")\n",
        "    print(f\"    - Min co-occurrence: {network_cfg.get('min_cooccurrence', 'N/A')}\")\n",
        "    print(f\"    - Weight method: {network_cfg.get('weight_method', 'N/A')}\")\n",
        "    print(f\"    - Min ingredient frequency: {network_cfg.get('min_ingredient_freq', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"Config file not found: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Recipe Data\n",
        "\n",
        "Load the final output from the preprocessing pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset shape: (63689, 8)\n",
            "Columns: ['Dataset_ID', 'index', 'ingredients', 'cuisine', 'inferred_ingredients', 'encoded_ingredients', 'cuisine_deduped', 'cuisine_encoded']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset_ID</th>\n",
              "      <th>index</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>inferred_ingredients</th>\n",
              "      <th>encoded_ingredients</th>\n",
              "      <th>cuisine_deduped</th>\n",
              "      <th>cuisine_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[buttermilk cornbread, sandwich bread, salt, b...</td>\n",
              "      <td>[Southern &amp; Soul Food]</td>\n",
              "      <td>[buttermilk cornbread, rice, salt water, peppe...</td>\n",
              "      <td>[16658, 155, 1456, 11, 506, 73, 23, 89, 6, 5, ...</td>\n",
              "      <td>[[southern &amp; soul food]]</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Country Crock® Spread, light corn syrup, crea...</td>\n",
              "      <td>[American]</td>\n",
              "      <td>[[, country, crock, spread, corn syrup, peanut...</td>\n",
              "      <td>[0, 533, 13950, 803, 162, 19, 1082, 378]</td>\n",
              "      <td>[[american]]</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[Skippy® Super Chunk® Peanut Butter, Country C...</td>\n",
              "      <td>[American]</td>\n",
              "      <td>[super chunk, ®, peanut, butter, country, croc...</td>\n",
              "      <td>[0, 0, 702, 6, 533, 13950, 803, 1082, 729]</td>\n",
              "      <td>[[american]]</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[light mayonnaise, lemon juice, cayenne pepper...</td>\n",
              "      <td>[American]</td>\n",
              "      <td>[mayonnaise, lemon juice, cayenne pepper, blue...</td>\n",
              "      <td>[66, 56, 345, 1760, 458, 22, 16]</td>\n",
              "      <td>[[american]]</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[elbow macaroni, hellmann' or best food real m...</td>\n",
              "      <td>[American]</td>\n",
              "      <td>[elbow, hellmann, red vinegar, wine, dijonnais...</td>\n",
              "      <td>[612, 49176, 103, 212, 49176, 3073, 3339, 1459...</td>\n",
              "      <td>[[american]]</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dataset_ID  index                                        ingredients  \\\n",
              "0           1      0  [buttermilk cornbread, sandwich bread, salt, b...   \n",
              "1           1      1  [Country Crock® Spread, light corn syrup, crea...   \n",
              "2           1      2  [Skippy® Super Chunk® Peanut Butter, Country C...   \n",
              "3           1      3  [light mayonnaise, lemon juice, cayenne pepper...   \n",
              "4           1      4  [elbow macaroni, hellmann' or best food real m...   \n",
              "\n",
              "                  cuisine                               inferred_ingredients  \\\n",
              "0  [Southern & Soul Food]  [buttermilk cornbread, rice, salt water, peppe...   \n",
              "1              [American]  [[, country, crock, spread, corn syrup, peanut...   \n",
              "2              [American]  [super chunk, ®, peanut, butter, country, croc...   \n",
              "3              [American]  [mayonnaise, lemon juice, cayenne pepper, blue...   \n",
              "4              [American]  [elbow, hellmann, red vinegar, wine, dijonnais...   \n",
              "\n",
              "                                 encoded_ingredients  \\\n",
              "0  [16658, 155, 1456, 11, 506, 73, 23, 89, 6, 5, ...   \n",
              "1           [0, 533, 13950, 803, 162, 19, 1082, 378]   \n",
              "2         [0, 0, 702, 6, 533, 13950, 803, 1082, 729]   \n",
              "3                   [66, 56, 345, 1760, 458, 22, 16]   \n",
              "4  [612, 49176, 103, 212, 49176, 3073, 3339, 1459...   \n",
              "\n",
              "            cuisine_deduped cuisine_encoded  \n",
              "0  [[southern & soul food]]             [0]  \n",
              "1              [[american]]             [0]  \n",
              "2              [[american]]             [0]  \n",
              "3              [[american]]             [0]  \n",
              "4              [[american]]             [0]  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from network.builder import NetworkBuilder\n",
        "\n",
        "# Initialize network builder\n",
        "builder = NetworkBuilder(\n",
        "    min_cooccurrence=network_cfg.get('min_cooccurrence', 1),\n",
        "    weight_method=network_cfg.get('weight_method', 'frequency'),\n",
        "    normalize_weights=network_cfg.get('normalize_weights', True),\n",
        "    min_ingredient_freq=network_cfg.get('min_ingredient_freq', 2),\n",
        ")\n",
        "\n",
        "# Load data\n",
        "input_path = Path(data_cfg.get('input_path', '../../preprocess_pipeline/data/encoded_combined_datasets_with_cuisine_encoded.parquet'))\n",
        "df = builder.load_data(input_path, ingredients_col=data_cfg.get('ingredients_col', 'encoded_ingredients'))\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.5: Diagnostic - Inspect Ingredients Data\n",
        "\n",
        "Before building the network, let's check the format and content of the ingredients column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diagnostic: Checking 'encoded_ingredients' column...\n",
            "\n",
            " Counting non-zero ingredients across all rows...\n",
            " Rows with non-zero ingredients: 61,521 / 63,689\n",
            " Total non-zero ingredient IDs found: 649,479\n",
            "\n",
            " Computing ingredient frequency (this may take a moment)...\n",
            " Unique non-zero ingredient IDs: 9,415\n",
            " Frequency distribution:\n",
            " Ingredients appearing 1 time(s): 2,566\n",
            " Ingredients appearing 2 time(s): 1,682\n",
            " Ingredients appearing 3 time(s): 769\n",
            " Ingredients appearing 4 time(s): 525\n",
            " Ingredients appearing 5 time(s): 367\n",
            " Ingredients appearing 6 time(s): 299\n",
            " Ingredients appearing 7 time(s): 222\n",
            " Ingredients appearing 8 time(s): 214\n",
            " Ingredients appearing 9 time(s): 157\n",
            " Ingredients appearing 10 time(s): 135\n",
            " Ingredients appearing >= 2 times: 6,849\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd # Assuming pd was imported earlier\n",
        "\n",
        "# --- (Previous code setup) ---\n",
        "\n",
        "# Diagnostic: Check ingredients column\n",
        "ingredients_col = data_cfg.get('ingredients_col', 'encoded_ingredients')\n",
        "print(f\"Diagnostic: Checking '{ingredients_col}' column...\")\n",
        "# ... (rest of the sample printing code is fine) ...\n",
        "\n",
        "# Count total non-zero ingredients across all rows\n",
        "print(f\"\\n Counting non-zero ingredients across all rows...\")\n",
        "nonzero_count = 0\n",
        "rows_with_ingredients = 0\n",
        "\n",
        "# --- FIX 1 (in the first loop) ---\n",
        "for idx, row in df.iterrows():\n",
        "    val = row[ingredients_col]\n",
        "    \n",
        "    # Check for the expected type *first*.\n",
        "    # This will safely skip np.nan, None, strings, etc.\n",
        "    if isinstance(val, (list, tuple, np.ndarray)):\n",
        "        ing_list = list(val)\n",
        "        non_zero = [i for i in ing_list if i and i != 0]\n",
        "        if len(non_zero) > 0:\n",
        "            rows_with_ingredients += 1\n",
        "        nonzero_count += len(non_zero)\n",
        "\n",
        "print(f\" Rows with non-zero ingredients: {rows_with_ingredients:,} / {len(df):,}\")\n",
        "print(f\" Total non-zero ingredient IDs found: {nonzero_count:,}\")\n",
        "\n",
        "# Check ingredient frequency distribution\n",
        "print(f\"\\n Computing ingredient frequency (this may take a moment)...\")\n",
        "ingredient_counter = Counter()\n",
        "\n",
        "# --- FIX 2 (in the second loop) ---\n",
        "for idx, row in df.iterrows():\n",
        "    val = row[ingredients_col]\n",
        "    \n",
        "    # Apply the same logic: check for type *first*.\n",
        "    if isinstance(val, (list, tuple, np.ndarray)):\n",
        "        for ing_id in val:\n",
        "            if ing_id and ing_id != 0:\n",
        "                ingredient_counter[ing_id] += 1\n",
        "\n",
        "print(f\" Unique non-zero ingredient IDs: {len(ingredient_counter):,}\")\n",
        "if len(ingredient_counter) > 0:\n",
        "    freq_dist = Counter(ingredient_counter.values())\n",
        "    print(f\" Frequency distribution:\")\n",
        "    for freq, count in sorted(freq_dist.items())[:10]:\n",
        "        print(f\" Ingredients appearing {freq} time(s): {count:,}\")\n",
        "        \n",
        "    # Assuming network_cfg is defined\n",
        "    min_freq = network_cfg.get('min_ingredient_freq', 2)\n",
        "    print(f\" Ingredients appearing >= {min_freq} times: {sum(1 for f in ingredient_counter.values() if f >= min_freq):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Build Network\n",
        "\n",
        "Compute co-occurrence statistics and build the ingredient network graph.\n",
        "\n",
        "**Note**: If the network has 0 nodes, check the diagnostic output above. You may need to:\n",
        "- Lower `min_ingredient_freq` in the config (currently filtering out ingredients that appear < 2 times)\n",
        "- Check if the ingredients column is being read correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Network built:\n",
            "  Nodes (ingredients): 6,849\n",
            "  Edges (co-occurrences): 438,742\n"
          ]
        }
      ],
      "source": [
        "# Compute statistics\n",
        "builder.compute_statistics(df, ingredients_col=data_cfg.get('ingredients_col', 'encoded_ingredients'))\n",
        "\n",
        "# Build graph\n",
        "graph = builder.build_graph()\n",
        "\n",
        "# Normalize weights if needed\n",
        "if network_cfg.get('normalize_weights', True):\n",
        "    graph = builder.normalize_graph_weights(graph)\n",
        "    builder.graph = graph  # Update builder's graph reference\n",
        "\n",
        "print(f\"\\nNetwork built:\")\n",
        "print(f\"  Nodes (ingredients): {graph.number_of_nodes():,}\")\n",
        "print(f\"  Edges (co-occurrences): {graph.number_of_edges():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Network\n",
        "\n",
        "Analyze network properties and identify important ingredients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Path-length statistics (diameter, average_path_length) skipped for performance. Graph has 6,849 nodes. These calculations require O(n^2) all-pairs shortest paths and can hang on large graphs.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A\n",
            "B\n",
            "C\n",
            "Network Statistics:\n",
            "  num_nodes: 6849\n",
            "  num_edges: 438742\n",
            "  density: 0.018708901497319345\n",
            "  is_connected: False\n",
            "  largest_component_size: 6842\n",
            "  diameter: 0\n",
            "  average_path_length: 0.0\n",
            "  avg_degree: 128.11855745364286\n",
            "  max_degree: 5437\n",
            "  min_degree: 0\n",
            "D\n",
            "E\n",
            "\n",
            "Top 10 ingredients by degree centrality:\n",
            "  Ingredient 1456: 0.7940\n",
            "  Ingredient 11: 0.6650\n",
            "  Ingredient 1082: 0.6202\n",
            "  Ingredient 179: 0.6189\n",
            "  Ingredient 6: 0.5869\n",
            "  Ingredient 23: 0.5853\n",
            "  Ingredient 158: 0.5605\n",
            "  Ingredient 5: 0.5483\n",
            "  Ingredient 28: 0.5409\n",
            "  Ingredient 9105: 0.5190\n"
          ]
        }
      ],
      "source": [
        "from network.analysis import NetworkAnalyzer\n",
        "from network.graph import IngredientGraph\n",
        "\n",
        "# Wrap graph in IngredientGraph for easier access\n",
        "print(\"A\")\n",
        "ing_graph = IngredientGraph(graph)\n",
        "print(\"B\")\n",
        "# Analyze network\n",
        "analyzer = NetworkAnalyzer(graph)\n",
        "print(\"C\")\n",
        "# Get network statistics\n",
        "stats = analyzer.get_network_statistics()\n",
        "print(\"Network Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"D\")\n",
        "# Compute centrality measures\n",
        "centralities = analyzer.compute_centrality_measures()\n",
        "print(\"E\")\n",
        "# Get top ingredients by degree\n",
        "top_ingredients = analyzer.get_top_ingredients('degree', top_k=10)\n",
        "print(f\"\\nTop 10 ingredients by degree centrality:\")\n",
        "for ing_id, score in top_ingredients:\n",
        "    print(f\"  Ingredient {ing_id}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Save Network\n",
        "\n",
        "Save the network for use in inference tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Network saved to: data\\ingredient_network.graphml\n",
            "Network is ready for use in inference tasks!\n"
          ]
        }
      ],
      "source": [
        "# Save graph\n",
        "graph_output = Path(network_cfg.get('graph_output', './data/ingredient_network.graphml'))\n",
        "builder.save_graph(graph_output, format='graphml')\n",
        "\n",
        "print(f\"\\nNetwork saved to: {graph_output}\")\n",
        "print(\"Network is ready for use in inference tasks!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
